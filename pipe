#!/usr/bin/env python
try:
    from plumbum import local, FG, cli
except ImportError:
    print('Couldn\'t import plumbum')
    print(
        'Did you forget to load python environment? (e.g. source activate pnlpipe)'
    )
import sys
import yaml
import itertools
import importlib
from collections import defaultdict
from pprint import pprint
import logging
# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)5s - %(name)s %(message)s', datefmt="%Y-%m-%d %H:%M")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)5s - %(name)s:  %(message)s', datefmt="%Y-%m-%d %H:%M")
logger = logging.getLogger(__name__)
import pipelib
import software

inputPathsFile = "srcpaths.yml"

def printTable(myDict, colList=None):
    """ Pretty print a list of dictionaries (myDict) as a dynamically sized table.
   Original from http://stackoverflow.com/questions/17330139/python-printing-a-dictionary-as-a-horizontal-table-with-headers
   """
    if not colList: colList = sorted(list(myDict[0].keys()) if myDict else [])
    myList = [colList]  # 1st row = header
    for item in myDict:
        myList.append([str(item[col] or '') for col in colList])
    colSize = [max(map(len, col)) for col in zip(*myList)]
    formatStr = ' | '.join(["{{:<{}}}".format(i) for i in colSize])
    myList.insert(1, ['-' * i for i in colSize])  # Seperating line
    for item in myList:
        print(formatStr.format(*item))


def printVertical(d, prepend='', fd=sys.stderr):
    for k, v in d.items():
       fd.write("{}{:<25} {:<15}".format(prepend,k, v) + '\n')


def readAndSetInputPaths():
    if not local.path(inputPathsFile).exists():
        raise Exception(
            "Missing {}, first make one using './pipe init' or a text editor".format(
                inputPathsFile))
    with open(inputPathsFile, 'r') as f:
        inputPathDict = yaml.load(f)
    pipelib.INPUT_PATHS = {}
    caseidPattern = inputPathDict.get('caseid', '{case}')
    for key, val in inputPathDict.items():
        if key == 'caseid' or key.startswith('version_') or key.startswith(
                'hash_'):
            continue
        pipelib.INPUT_PATHS[key] = local.path(
            val.replace(caseidPattern, '{case}'))
    logging.info("Read '{}' and set pipelib.INPUT_PATHS:".format(inputPathsFile))
    printVertical(pipelib.INPUT_PATHS)
    # pprint(pipelib.INPUT_PATHS)


class App(cli.Application):
    def main(self, *args):
        if args:
            print("Unknown command {0!r}".format(args[0]))
            return 1
        if not self.nested_command:
            print("No command given")
            return 1  # error exit code


def checkPaths(pathsDict):
    allexist = True
    logging.info('Check keys')
    for key, path in pathsDict.items():
        logging.info('{}: {}'.format(key, path))
        if key == 'caseid':
            continue
        if not local.path(path).exists():
            logging.warning("'{}' does not exist, is this intended?".format(path))
            allexist = False
    if not pathsDict.get('caseid', None):
        errmsg = """'caseid' not set, make you set this so the pipeline knows how to get the paths for your other subjects.
'{}' not made""".format(inputPathsFile)
        raise Exception(errmsg)
    if allexist:
        logging.info('All paths exist.')
        return
    logging.warning(
        "Warning: Some paths don't exist for the given caseid, so pipeline may fail to run."
    )


def writePaths(pathsDict, outfile):
    checkPaths(pathsDict)
    with open(outfile, 'w') as f:
        yaml.safe_dump(pathsDict, f, default_flow_style=False)
    logging.info("Made '{}'".format(outfile))


def readPathsYml(pathsDir):
    pathsDict = {}
    with open(pathsDir / 'paths.yml', 'r') as f:
        try:
            relativePaths = yaml.load(f, Loader=yaml.loader.BaseLoader)
        except yaml.parser.ParserError, e:
            loggin.error(
                'Error parsing {}, is there a typo? (And are the path templates in quotes?)'.format(
                    pathsDir / 'paths.yml'), exc_info=True)
            sys.exit(1)
    return relativePaths


@App.subcommand("init")
class PipeInit(cli.Application):
    """Creates input paths yaml file for this project."""

    fromdir = cli.SwitchAttr(
        '--fromdir',
        cli.ExistingDirectory,
        help='from data directory with existing paths.yml')

    def main(self):
        if local.path(inputPathsFile).exists():
            logging.info(
                "'{}' already exists, won't overwrite.".format(inputPathsFile))
            return

        # Copy from paths.yml in another project directory
        if self.fromdir:
            dataDir = self.fromdir
            inputPaths = {}
            for key, val in readPathsYml(dataDir).items():
                if key == 'caseid':
                    inputPaths[key] = val
                else:
                    absolutePath = local.path(dataDir / val)
                    newPath = absolutePath.relative_to(
                        local.path(inputPathsFile).dirname)
                    inputPaths[key] = str(newPath)
            writePaths(inputPaths, inputPathsFile)

        # Ncurses interface
        else:
            try:
                import npyscreen

                class MakePathsApp(npyscreen.NPSApp):
                    def main(self):
                        F = npyscreen.Form(
                            name="Make a paths yaml file (TAB to autocomplete and ENTER/up/down to change fields", )
                        self.dwi = F.add(npyscreen.TitleFilename,
                                         name="dwi:",
                                         begin_entry_at=24)
                        self.t1 = F.add(npyscreen.TitleFilename,
                                        name="t1:",
                                        begin_entry_at=24)
                        #self.dwimask = F.add(npyscreen.TitleFilename, name = "dwimask:", begin_entry_at=24)
                        self.t2 = F.add(npyscreen.TitleFilename,
                                        name="t2:",
                                        begin_entry_at=24)
                        self.caseid = F.add(npyscreen.TitleText,
                                            name="caseid:",
                                            begin_entry_at=24)

                        # This lets the user interact with the Form.
                        F.edit()

                NcursesApp = MakePathsApp()
                NcursesApp.run()
                inputPaths = {'caseid': NcursesApp.caseid.value}
                for key in ['dwi', 't1', 't2']:
                    if getattr(NcursesApp, key).value:
                        inputPaths[key] = getattr(NcursesApp, key).value
                writePaths(inputPaths, inputPathsFile)
            except ImportError:
                raise Exception(
                    """Could not import npyscreen for ncurses interface, instead use a
text editor to make the yaml file ({}), with this format:

    t1: /project/dir/001/001-t1.ext
    dwi: /project/dir/001/001-dwi.ext
    caseid: 001""".format(inputPathsFile))


def concat(l):
    return l if l == [] else [item for sublist in l for item in sublist]


def readParams(ymlfile):

    if not local.path(ymlfile).exists():
        pipeline = ymlfile.name.split('.')[1]
        raise Exception("'{}' doesn't exist, run './pipe {} init' first".format(
            ymlfile, pipeline))
    with open(ymlfile, 'r') as f:
        yml = yaml.load(f)

    result = []
    for idx, paramDict in enumerate(yml if isinstance(yml, list) else [yml]):
        listValueDict = dict((k, v) if isinstance(v, list) else (k, [v])
                             for k, v in paramDict.items())
        if not paramDict.get('caseid'):
            caselist = local.path('caselist.txt')
            if not caselist.exists():
                raise Exception(
                    "Add 'caseid' to {} (or save a caselist.txt to this directory)".format(
                        ymlfile))
            logging.info("Found './caselist.txt, using that for case id's")
            listValueDict['caseid'] = ['./caselist.txt']
        result.append(listValueDict)

    logging.info("Read parameter file '{}':".format(ymlfile))
    for d in result:
        printVertical(d)
    return result


def checkParams(paramDicts):
    if '*mandatory*' in concat([concat(d.values()) for d in paramDicts]):
        raise Exception(
            "First replace '*mandatory*' values in params file and then run again."
        )


def expandParams(params):
    paramPoints = []
    for paramsDict in params:
        # Check if case ids are defined by a caselist
        if '/' in paramsDict['caseid'][0]:
            with open(paramsDict['caseid'][0], 'r') as f:
                paramsDict['caseid'] = f.read().splitlines()
        keys = paramsDict.keys()
        valueCombos = list(itertools.product(*paramsDict.values()))
        ps = [dict(zip(keys, combo)) for combo in valueCombos]
        paramPoints.append(ps)
    # return list of unique parameters
    return list({yaml.dump(p): p for p in concat(paramPoints)}.values())


class PipelineSubcommand(cli.Application):
    def main(self, *args):
        if args:
            print("Unknown command {0!r}".format(args[0]))
            return 1
        if not self.nested_command:
            print("No command given")
            return 1  # error exit code


class Run(cli.Application):

    want = cli.SwitchAttr(
        ['-w', '--want'], help='target node to build, e.g. fsindwi')

    def main(self, *caseids):
        readAndSetInputPaths()  # reads source paths into pipelib.INPUT_PATHS

        paramDicts = readParams(self.parent.paramsFile)
        if any('*mandatory*' in concat(p.values()) for p in paramDicts):
            raise Exception(
                "'{}' has unfilled mandatory values, replace the '*mandatory*' fields first and then rerun the pipeline.".format(
                    self.parent.paramsFile))

        if caseids:
            for paramsDict in paramDicts:
                if 'caseid' in paramsDict.keys():
                    paramsDict['caseid'] = caseids

        paramsList = expandParams(paramDicts)

        logging.info('Check that prerequisite software exists')
        missingSoftwareModules = []
        missingSoftware = []
        for softname, version, moduleFile in softwareItems(list(set(filter(lambda x: not isinstance(x[1],list), concat([p.items() for p in paramsList]))))):
            if not moduleFile.exists():
                missingSoftwareModules.append(moduleFile)
                continue
            module = importlib.import_module('software.' + softname)
            if not local.path(module.getPath(version)).exists():
                missingSoftware.append(module.getPath(version))

        for f in missingSoftwareModules:
            logging.warning("missing {}".format(f))
        for p in missingSoftware:
            logging.warning("missing: {}".format(p))
        if missingSoftwareModules:
            sys.exit(1)
        if missingSoftware:
            errmsg = """
Some software components are missing so some parts of the pipeline won't run.
Run './pipe {} make' to build all prequisite software.".format(self.parent.name
            """.format(self.parent.name)
            raise Exception(errmsg)

        for params in paramsList:
            logging.info(
                'Running {} pipeline with parameters:'.format(self.parent.name)
            )
            printVertical(params)

            pipeline = self.parent.makePipeline(**params)

            if not self.want:
                if not self.parent.defaultTarget:
                    errmsg = """
'pipelines/pipeline_{}.py' doesn't have 'DEFAULT_TARGET' defined, set this in 'makePipeline(...)'."
E.g. DEFAULT_TARGET = 'tractmeasures'""" .format(self.parent.name, self.parent.name)
                    raise Exception(errmsg)
                pipelib.update(pipeline[self.parent.defaultTarget])
            else:
                pipelib.update(pipeline[self.want])


def softwareItems(items):
    for key, val in items:
        if key.startswith('hash_'):
            softname = key[5:]
        elif key.startswith('version_'):
            softname = key[8:]
        else:
            continue
        moduleFile = local.path('software') / (softname + '.py')
        yield (softname, val, moduleFile)


def getRequiredSoftwareModules(yml):
    for paramsDict in yml:
        for softname, commits, moduleFile in softwareItems(paramsDict.items()):
            if not moduleFile.exists():
                raise Exception("{} does not exist".format(moduleFile))
            module = importlib.import_module('software.' + softname)
            for commit in commits:
                yield (module, commit)


class Init(cli.Application):
    """Makes parameter file that is used as input for this pipeline."""

    force = cli.Flag(
        ['--force'], help='Force overwrite existing parameter file.')

    def main(self):

        pipelineName = self.parent.__class__.__name__
        paramsFile = self.parent.paramsFile
        if paramsFile.exists() and not self.force:
            print(
                "'{}' already exists, won't overwrite (use '--force' to overwrite it).".format(
                    paramsFile))
            return
        local.path(paramsFile).delete()
        import inspect
        from itertools import izip_longest
        from collections import OrderedDict
        args, _, _, defaults = inspect.getargspec(
            self.parent.makePipeline_orig)
        if defaults:
            x = izip_longest(
                reversed(args), reversed(defaults), fillvalue='*mandatory*')
        else:
            x = izip_longest(reversed(args), [], fillvalue='*mandatory*')
        # paramDict = OrderedDict(reversed(list(x)))
        paramDict = OrderedDict(reversed(map(lambda y: (y[0],[y[1]]), x)))
        # get a default caseid
        paramDict['caseid'] = ['./caselist.txt']
        if (not local.path('caselist.txt').exists()
            ) and local.path(inputPathsFile).exists():
            with open(inputPathsFile, 'r') as f:
                inputPaths = yaml.load(f)
                if not isinstance(inputPaths, dict):
                    errmsg = """Error reading {} as a dictionary, is it in the correct format?                    E.g.
dwi: path/to/001-dwi.nrrd
t1: path/to/001-t1.nrrd
caseid: caseid""" .format(inputPathsFile)
                    raise Exception(errmsg)
                paramDict['caseid'] = [inputPaths.get('caseid',
                                                     './caselist.txt')]
        """ http://stackoverflow.com/a/8661021 """
        represent_dict_order = lambda self, data: self.represent_mapping('tag:yaml.org,2002:map', data.items())
        yaml.add_representer(OrderedDict, represent_dict_order)
        help_message = \
"""# Use one of the following formats for 'caseid'
#    caseid: '001'
#    caseid: ['001', '002', '003']
#    caseid:
#       - '001'
#       - '002'
#       - '003'
#    caseid: ./caselist-controls.txt  # The '/' tells pipe that this is a file
#
# Note that you need to wrap your caseid in quotes if it is an integer like
# above, otherwise the yaml reader will read them as 1, 2, 3, etc. instead of
# '001', '002', '003'.
#
# The values for keys like dwiKey come from the names in srcpaths.yml. For
# example,
#    dwiKey: ['dwiharmonized', 'dwi']
# means that the pipeline will be run for the filepaths of 'dwiharmonized' and
# 'dwi' in srcpaths.yml (caseid will automatically be substituted). These are
# meant to be descriptive names that describe your input paths and are used in
# naming the generated output.

"""
        with open(paramsFile, 'w') as f:
            f.write(help_message)
            yaml.dump(paramDict, f, default_flow_style=None)
        print("Made '{}'".format(paramsFile))
        print("Before running the pipeline, replace the '*mandatory*' fields:")
        print("# Edit {}, add your parameters".format(paramsFile))
        print("./pipe {} make".format(pipelineName))
        print("./pipe {} run".format(pipelineName))


class Make(cli.Application):
    """ Builds necessary software for pipeline. """

    def main(self):
        if not self.parent.paramsFile.exists():
            raise Exception(
                "'{}' doesn't exist, make it first with './pipe {} init'".format(
                    self.parent.paramsFile, self.parent.__class__.__name__))

        # Build prerequisite software
        paramDicts = readParams(self.parent.paramsFile)
        for module, commit in getRequiredSoftwareModules(paramDicts):
            logging.info("Make {}".format(module.getPath(commit)))
            module.make(commit)

        # Make shell environment files
        logging.info("Make shell environment files")
        makeEnvFiles(self.parent.name, self.parent.paramsFile, self.parent.makePipeline)


def groupDicts(dicts, keyfn):
    from itertools import groupby
    return [(k, list(g)) for k, g in groupby(sorted(dicts, key=keyfn), keyfn)]


def makeRelativeSymlink(src, symlink):
    import os
    os.symlink(os.path.relpath(src, os.path.dirname(symlink)), symlink)

def escapePath(filepath):
    return filepath.__str__().replace('(', '\(').replace(')', '\)')

# def makeSetUpData(makePipelineFn, caseid, paramPoints):
#     def quote(s):
#         return s.replace('(', '\(').replace(')', '\)')
#     with open('SetUpData.sh', 'w') as f:
#         for i, param in enumerate(paramPoints):
#             print param
#             caseid = param['caseid']
#             pipeline = makePipelineFn(**param)
#             for key, node in pipeline.items():
#                 if key == 'all' or key == 'name':
#                     continue
#                 idx = '' if i == 0 else str(i + 1)
#                 shortName = key + idx + ''.join(node.path().suffixes)
#                 pathTemplate = quote(node.path().replace(caseid, '$case'))
#                 line = "{}={}".format(key + idx, pathTemplate)
#                 f.write(line + '\n')


def makeEnvFiles(name, paramsFile, makePipelineFn):
    # first delete existing files in case they are stale
    for f in local.cwd.glob(name + '*.sh'):
        f.delete()
    # with open('outputPaths.yml', 'w') as fyml:
    for comboPaths in pipelineComboPaths(paramsFile, makePipelineFn):
        envFile = "_{}_env{}.sh".format(name, comboPaths['id'])
        logging.info("Make '{}'".format(envFile))
        with open(envFile, 'w') as f:
            f.write('# Parameter combination {}\n'.format(comboPaths['id']))
            printVertical(comboPaths['paramCombo'],'#  ', f)
            f.write('\n')

            # Generated output paths
            for key, subjectPaths in comboPaths['paths'].iteritems():
                f.write('{}={}\n\n'.format(key, escapePath(subjectPaths[0].path)))
                # fyml.write('{}: {}\n'.format(key, subjectPaths[0].path.relative_to(local.cwd)))
            f.write('caseid={}\n\n'.format(subjectPaths[0].caseid))
            # fyml.write('caseid: {}\n'.format(subjectPaths[0].caseid))

            # Software environment
            envDicts = []
            for softname, version, _ in softwareItems(comboPaths['paramCombo'].items()):
                m = importlib.import_module('software.' + softname)
                if hasattr(m, 'envDict'):
                    envDicts.append(m.envDict(version))
            softVars = software.composeEnvDicts(envDicts)
            for var, val in softVars.items():
                f.write('{}={}\n\n'.format(var, val))
            f.write("PATH={}:$PATH\n".format(local.path('pipelines/pnlscripts')))
        # sys.stdout.write("Done.\n".format(envFile))
        logging.info("Made '{}'".format(envFile))
    # print("Made '{}'".format('outputPaths.yml'))


class SymLink(cli.Application):
    """Makes simply named symlinks to fully named nodes"""

    def main(self):
        pipename = self.parent.name
        for symlink in (pipelib.OUTDIR // '*/{}_*'.format(self.parent.name)):
            symlink.delete()
        for comboPaths in pipelineComboPaths(self.parent.paramsFile,
                                             self.parent.makePipeline):
            logging.info("# Make symlinks for parameter combination {}".format(
                comboPaths['id']))
            printVertical(comboPaths['paramCombo'])
            for key, subjectPaths in comboPaths['paths'].iteritems():
                existingPaths = [
                    p for p in filter(lambda x: x.path.exists(), subjectPaths)
                ]
                for p in existingPaths:
                    symlink = local.path(pipelib.OUTDIR / p.caseid /
                                         (pipename + '_' + key + ''.join(p.path.suffixes)))
                    sys.stdout.write("Make symlink '{}' --> '{}' ".format(
                        symlink, p.path))
                    if symlink.exists():
                        sys.stdout.write('(Already exists, skipping)\n')
                        continue
                    sys.stdout.write('\n')
                    symlink.dirname.mkdir()
                    makeRelativeSymlink(p.path, symlink)


def getSoftwareModules():
    import pkgutil
    from os.path import isfile
    import software
    for importer, modname, ispkg in pkgutil.iter_modules(software.__path__):
        yield importer.find_module(modname).load_module(modname)


def loadSoftwareModule(name):
    moduleFile = local.path('software') / (name + '.py')
    if not moduleFile.exists():
        raise Exception(
            "{} does not exist, is there a typo (e.g. in the params file?)".format(
                moduleFile))
    return importlib.import_module('software.' + name)


@App.subcommand('soft')
class SoftwareCommand(cli.Application):
    ver = cli.SwitchAttr(['-v', '--version'], help='Software version')

    def main(self, softname):
        if not softname:
            logging.info("Missing software module argument, e.g. BRAINSTools")
            return 1
        softwareModule = loadSoftwareModule(softname)
        if self.ver:
            logging.info("Make '{}'".format(softwareModule.getPath(self.ver)))
            softwareModule.make(self.ver)
        else:
            logging.info("Make '{}'".format(softwareModule.getPath()))
            softwareModule.make()

def pipelineNodeItems(pipeline):
    items = filter(lambda x: not x[0].startswith('_'), pipeline.items())
    for item in items:
        if not hasattr(item[1], 'build') or not hasattr(item[1], 'path'):
            raise Exception(
                "The object at key '{}' is not a Node, are you missing a leading '_'?".format(
                    item[0]))
    return items


def groupParamPointsByCombo(paramsFile):
    readAndSetInputPaths()
    paramDicts = readParams(paramsFile)
    checkParams(paramDicts)
    paramPoints = expandParams(paramDicts)
    paramPointsByCombo = groupDicts(paramPoints, lambda x: {k:v for k,v in x.items() if k != 'caseid'} )
    # Sort by parameter points that have most caseids. This is an edge
    # case, usually there will only be one parameter point, or if more than
    # one they will be the same length. But, there is a use case hen
    # running a smaller test set to see the effect of a change in one of
    # the parameters, e.g. a different software version
    paramPointsByCombo = sorted(paramPointsByCombo, key=lambda x: -len(x[1]))
    return paramPointsByCombo


from collections import namedtuple
SubjectPath = namedtuple('SubjectPath', 'caseid path')


def pipelineComboPaths(paramsFile, makePipelineFn):
    paramPointsByCombo = groupParamPointsByCombo(paramsFile)
    result = []
    # for each parameter values combo (a parameter point without caseid)
    for i, (paramCombo, paramPoints) in enumerate(paramPointsByCombo):
        iStr = '' if i == 0 else str(i)
        pipelinePaths = {'paramCombo': paramCombo,
                         'paramPoints': paramPoints,
                         'paths': defaultdict(list),
                         'id': i,
                         'num': len(paramPoints)}
        # for each subject
        for paramPoint in paramPoints:
            pipeline = makePipelineFn(**paramPoint)
            for key, node in pipelineNodeItems(pipeline):
                p = SubjectPath(caseid=paramPoint['caseid'], path=node.path())
                pipelinePaths['paths'][key + iStr].append(p)
        result.append(pipelinePaths)
    return result


class Status(cli.Application):
    def main(self):
        for comboPaths in pipelineComboPaths(self.parent.paramsFile,
                                             self.parent.makePipeline):
            logging.info("## Parameter Combination {} ({} subjects)".format(
                comboPaths['id'], comboPaths['num']))

            printVertical(comboPaths['paramCombo'])
            d = {k: len(filter(lambda x: x.path.exists(), vs))
                 for k, vs in comboPaths['paths'].iteritems()}
            printTable([d])

            # call pipeline's custom status
            if hasattr(self.parent, 'status'):
                #print("{}'s custom status result:".format(self.parent.name))
                self.parent.status(comboPaths['paramPoints'])


class Ls(cli.Application):
    caseids = cli.Flag(
        ['-s', '--subjid'], help="Print subject ids instead of paths")
    printFull = cli.Flag(
        ['-p'], help="Print full paths instead of symlinks.")
    def main(self, *keys):
        for comboPaths in pipelineComboPaths(self.parent.paramsFile,
                                             self.parent.makePipeline):
            logging.info("## Parameter Combination {} ({} subjects)".format(
                comboPaths['id'], comboPaths['num']))
            printVertical(comboPaths['paramCombo'])
            for k, vs in comboPaths['paths'].iteritems():
                if keys and k not in keys:
                    continue
                existingPaths = [p
                                 for p in filter(lambda x: x.path.exists(), vs)
                                 ]
                for p in existingPaths:
                    if self.caseids:
                        print('{}'.format(p.caseid))
                    elif self.printFull:
                        print(p.path)
                    else:
                        symlink = local.path(pipelib.OUTDIR / p.caseid /
                                         (self.parent.name + '_' + k + ''.join(p.path.suffixes)))
                        print(symlink)


class Missing(cli.Application):
    """Print missing generated output."""

    caseids = cli.Flag(
        ['-s', '--subjid'], help="Print subject ids instead of paths")
    printFull = cli.Flag(
        ['-p'], help="Print full paths instead of symlinks.")

    def main(self, *keys):

        from itertools import cycle
        defaultKeys = [a + str(
            b) for a, b in zip(cycle([self.parent.defaultTarget]), range(1, 5))
                       ] + [self.parent.defaultTarget]
        keys = defaultKeys if not keys else keys
        if not keys:
            raise Exception(
                "'DEFAULT_TARGET' not set in 'pipelines/pipeline_{}.py', so you must provide a key on the command line, e.g. ./pipe std missing fs".format(
                    self.parent.name))

        for comboPaths in pipelineComboPaths(self.parent.paramsFile,
                                             self.parent.makePipeline):
            logging.info("## Parameter Combination {} ({} subjects)".format(
                comboPaths['id'], comboPaths['num']))
            printVertical(comboPaths['paramCombo'])

            for k, vs in comboPaths['paths'].iteritems():
                if k not in keys:
                    continue
                missingPaths = [
                    p for p in filter(lambda x: not x.path.exists(), vs)
                ]
                for p in missingPaths:
                    if self.caseids:
                        print('{}'.format(p.caseid))
                    elif self.printFull:
                        print(p.path)
                    else:
                        symlink = local.path(pipelib.OUTDIR / p.caseid /
                                         (self.parent.name + '_' + k + ''.join(p.path.suffixes)))
                        print(symlink)


def classSoftwareFactory(name, makeFn, BaseClass=SoftwareCommand):
    def wrapFunction(self, *args, **kwargs):
        return make(*args, **kwargs)

    newclass = type(name, (BaseClass, ), {"make": wrapFunction})
    return newclass


def pipelineModules():
    import pkgutil
    import pipelines
    from os.path import isfile
    for importer, modname, ispkg in pkgutil.iter_modules(pipelines.__path__):
        if modname.startswith('pipeline_'):
            yield importer.find_module(modname).load_module(modname)


def classFactory(name,
                 makePipelineFn,
                 statusFn,
                 defaultTarget,
                 BaseClass=PipelineSubcommand):
    def wrappedMakePipeline(self, *args, **kwargs):
        return makePipelineFn(*args, **kwargs)

    paramsFile = local.path(name + '.params')
    newclass = type(name, (BaseClass, ), {"name": name,
                                          "makePipeline": wrappedMakePipeline,
                                          "makePipeline_orig": makePipelineFn,
                                          "paramsFile": paramsFile,
                                          "defaultTarget": defaultTarget})

    if statusFn:

        def wrappedStatus(self, *args, **kwargs):
            return statusFn(*args, **kwargs)

        setattr(newclass, 'status', wrappedStatus)
    return newclass


if __name__ == '__main__':
    for m in pipelineModules():
        name = m.__name__[9:]
        statusFn = getattr(m, 'status', None)
        defaultTarget = getattr(m, 'DEFAULT_TARGET', None)
        SubcommandClass = classFactory(name, m.makePipeline, statusFn,
                                       defaultTarget)
        App.subcommand(name, SubcommandClass)
        SubcommandClass.subcommand("run", Run)
        SubcommandClass.subcommand("make", Make)
        SubcommandClass.subcommand("init", Init)
        SubcommandClass.subcommand("symlink", SymLink)
        SubcommandClass.subcommand("status", Status)
        SubcommandClass.subcommand("ls", Ls)
        SubcommandClass.subcommand("missing", Missing)
    App.run()
